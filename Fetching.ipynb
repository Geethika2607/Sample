{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd52bfaa-36b8-4bb7-9f5f-9fc74f7df5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Labels:\n",
      "Label: Text (Confidence: 0.95)\n",
      "Label: Screenshot (Confidence: 0.93)\n",
      "Label: Number (Confidence: 0.92)\n",
      "Label: Font (Confidence: 0.90)\n",
      "Label: Web page (Confidence: 0.87)\n",
      "Label: Website (Confidence: 0.79)\n",
      "Label: Software (Confidence: 0.66)\n",
      "Label: Computer program (Confidence: 0.61)\n",
      "Label: Sign (Confidence: 0.61)\n",
      "Label: Document (Confidence: 0.59)\n",
      "\n",
      "Detected Objects:\n",
      "\n",
      "Detected Logos:\n",
      "Logo: Amazon.com (Confidence: 0.72)\n",
      "\n",
      "Detected Text (Brand/Model Info):\n",
      "Extracted Text: amazonassociates\n",
      "Creating Your Amazon Associates Account\n",
      "English - EN\n",
      "Hi Geethika k\n",
      "Account Information\n",
      "Website and Mobile App List\n",
      "Profile\n",
      "Start Using Associates Central\n",
      "Congrats, Geethika k\n",
      "Thank you for applying to the Amazon.com Associates Program\n",
      "Your unique Associate ID is geethikak-20\n",
      "You may occasionally need to provide your Associate ID to verify your account with us. Your application will be\n",
      "reviewed shortly after you've referred qualified sales to Amazon.com.\n",
      "In the meantime, you have been granted the full access to Associates Central 24 hours a day.\n",
      "If your affiliate links have not referred qualified sales after 180 days, your application and access to Associates Central\n",
      "will be withdrawn.\n",
      "Don't get left out of the conversation, follow Associates on Facebook, YouTube, LinkedIn, and Twitter. We share tips,\n",
      "tutorials and trending promotions to help you succeed in the program.\n",
      "As a reminder, you must transparently disclose your relationship with us to customers when using Amazon links. For\n",
      "more information about how to do that, see the Help content here.\n",
      "Enter your Payment and Tax Information\n",
      "Now\n",
      "Later\n",
      "\n",
      "Dominant Colors:\n",
      "RGB: (244, 243, 242) → Color: White (Confidence: 0.43)\n",
      "RGB: (222, 236, 205) → Color: Silver (Confidence: 0.04)\n",
      "RGB: (197, 195, 195) → Color: Silver (Confidence: 0.37)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import vision\n",
    "\n",
    "# Set Google Cloud credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"sunny-furnace-450323-j7-fb55f0c1398a.json\"\n",
    "\n",
    "def detect_image_features(path):\n",
    "    \"\"\"Detects labels, objects, logos, text, dominant colors, and faces.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    # Label Detection\n",
    "    label_response = client.label_detection(image=image)\n",
    "    labels = label_response.label_annotations\n",
    "    print(\"Detected Labels:\")\n",
    "    for label in labels:\n",
    "        print(f\"Label: {label.description} (Confidence: {label.score:.2f})\")\n",
    "\n",
    "    # Object Detection\n",
    "    object_response = client.object_localization(image=image)\n",
    "    objects = object_response.localized_object_annotations\n",
    "    print(f\"\\nDetected Objects:\")\n",
    "    for obj in objects:\n",
    "        print(f\"Object: {obj.name} (Confidence: {obj.score:.2f})\")\n",
    "\n",
    "    # Logo Detection (Brand Extraction)\n",
    "    logo_response = client.logo_detection(image=image)\n",
    "    logos = logo_response.logo_annotations\n",
    "    print(f\"\\nDetected Logos:\")\n",
    "    if logos:\n",
    "        for logo in logos:\n",
    "            print(f\"Logo: {logo.description} (Confidence: {logo.score:.2f})\")\n",
    "    else:\n",
    "        print(\"No logos detected.\")\n",
    "\n",
    "    # OCR - Text Detection (Brand/Model Extraction)\n",
    "    text_response = client.text_detection(image=image)\n",
    "    texts = text_response.text_annotations\n",
    "    print(f\"\\nDetected Text (Brand/Model Info):\")\n",
    "    if texts:\n",
    "        print(f\"Extracted Text: {texts[0].description}\")\n",
    "    else:\n",
    "        print(\"No text detected.\")\n",
    "\n",
    "\n",
    "    from math import sqrt\n",
    "    \n",
    "    # Define a dictionary of basic color names with their approximate RGB values\n",
    "    COLOR_NAMES = {\n",
    "        \"Black\": (0, 0, 0),\n",
    "        \"White\": (255, 255, 255),\n",
    "        \"Red\": (255, 0, 0),\n",
    "        \"Lime\": (0, 255, 0),\n",
    "        \"Blue\": (0, 0, 255),\n",
    "        \"Yellow\": (255, 255, 0),\n",
    "        \"Cyan\": (0, 255, 255),\n",
    "        \"Magenta\": (255, 0, 255),\n",
    "        \"Silver\": (192, 192, 192),\n",
    "        \"Gray\": (128, 128, 128),\n",
    "        \"Maroon\": (128, 0, 0),\n",
    "        \"Olive\": (128, 128, 0),\n",
    "        \"Green\": (0, 128, 0),\n",
    "        \"Purple\": (128, 0, 128),\n",
    "        \"Teal\": (0, 128, 128),\n",
    "        \"Navy\": (0, 0, 128),\n",
    "        \"Orange\": (255, 165, 0),\n",
    "        \"Pink\": (255, 192, 203),\n",
    "        \"Brown\": (165, 42, 42),\n",
    "        \"Gold\": (255, 215, 0)\n",
    "    }\n",
    "\n",
    "    def closest_color(requested_color):\n",
    "        \"\"\"Find the closest human-readable color name for an RGB value.\"\"\"\n",
    "        min_distance = float(\"inf\")\n",
    "        closest_name = None\n",
    "        for name, rgb in COLOR_NAMES.items():\n",
    "            distance = sqrt((rgb[0] - requested_color[0]) ** 2 + \n",
    "                            (rgb[1] - requested_color[1]) ** 2 + \n",
    "                            (rgb[2] - requested_color[2]) ** 2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_name = name\n",
    "        return closest_name\n",
    "    \n",
    "    # Color Detection\n",
    "    image_props_response = client.image_properties(image=image)\n",
    "    props = image_props_response.image_properties_annotation\n",
    "    \n",
    "    print(\"\\nDominant Colors:\")\n",
    "    for color in props.dominant_colors.colors[:3]:  # Get top 3 colors\n",
    "        rgb_value = (int(color.color.red), int(color.color.green), int(color.color.blue))\n",
    "        color_name = closest_color(rgb_value)  # Convert RGB to color name\n",
    "        print(f\"RGB: {rgb_value} → Color: {color_name} (Confidence: {color.score:.2f})\")\n",
    "\n",
    "\n",
    "# Run detection\n",
    "detect_image_features('amazon.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107d78a-409c-4170-b5fe-46f35c5108cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
